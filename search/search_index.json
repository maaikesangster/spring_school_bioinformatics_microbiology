{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Spring School Bioinformatics and computational approaches in Microbiology Overview This Spring School is co-organized by the NCCR AntiResist , NCCR Microbiomes and the SIB PhD Training Network . The goal of this joint School is to provide PhD students and postdocs with theoretical and mostly hands-on knowledge on selected topics about microbiome and antibiotics resistance. In particular, the participants will be split into four groups to work on mini-projects, which will address the following topics: Project 1: Modeling antibiotic resistance evolution. Project 2: Computational image analysis: transforming images into insights. Project 3: Profiling and modeling the colorectal cancer microbiome. Project 4: Mathematical modeling of bacterial metabolism. Audience This course is addressed to life scientists (mostly PhD students and Postdocs) dealing with microbiology topics such as microbiomes and resistance to antibiotics. Learning outcomes At the end of the course, the participants are expected to: have a good understanding of the most common methods used during the event; repeat the same type of analysis achieved during the mini-project; present the mini-project and more globally disseminate their experience to the members of their group. Hotel Hotel and Conference Center Sempachersee Guido A. Z\u00e4ch Strasse 2 6207 Nottwil LU T +41 41 939 23 23 info -at- hotelsempachersee.ch How to get there","title":"Home"},{"location":"#spring-school-bioinformatics-and-computational-approaches-in-microbiology","text":"","title":"Spring School Bioinformatics and computational approaches in Microbiology"},{"location":"#overview","text":"This Spring School is co-organized by the NCCR AntiResist , NCCR Microbiomes and the SIB PhD Training Network . The goal of this joint School is to provide PhD students and postdocs with theoretical and mostly hands-on knowledge on selected topics about microbiome and antibiotics resistance. In particular, the participants will be split into four groups to work on mini-projects, which will address the following topics: Project 1: Modeling antibiotic resistance evolution. Project 2: Computational image analysis: transforming images into insights. Project 3: Profiling and modeling the colorectal cancer microbiome. Project 4: Mathematical modeling of bacterial metabolism.","title":"Overview"},{"location":"#audience","text":"This course is addressed to life scientists (mostly PhD students and Postdocs) dealing with microbiology topics such as microbiomes and resistance to antibiotics.","title":"Audience"},{"location":"#learning-outcomes","text":"At the end of the course, the participants are expected to: have a good understanding of the most common methods used during the event; repeat the same type of analysis achieved during the mini-project; present the mini-project and more globally disseminate their experience to the members of their group.","title":"Learning outcomes"},{"location":"#hotel","text":"Hotel and Conference Center Sempachersee Guido A. Z\u00e4ch Strasse 2 6207 Nottwil LU T +41 41 939 23 23 info -at- hotelsempachersee.ch How to get there","title":"Hotel"},{"location":"course_schedule/","text":"Schedule ONGOING WORK Sunday 8 May (~18h00) start end topic ~18:00 Arrival & check-in 19:00 Dinner Monday 9 May start end topic 09:00 09:30 Introduction by the 3 organizing partners about the event 09:30 10:30 Lecture Topic 1 - Modeling antibiotic resistance evolution 10:30 11:00 Coffee Break 11:00 12:00 Lecture Topic 2 - Computational image analysis: transforming images into insights 12:15 13:45 Lunch 13:45 14:45 Lecture Topic 3 - Profiling and modeling the colorectal cancer microbiome 14:45 15:45 Lecture Topic 4 - Mathematical modeling of bacterial metabolism: diauxic growth of a population and syntrophic interactions in a consortium 15:45 16:15 Coffee break 16:15 17:00 Preparation for the mini-projects Tuesday 10 May start end topic 09:00 10:30 Mini-projects (work in groups) 10:30 11:00 Coffee Break 11:00 12:30 Mini-projects (work in groups) 12:30 14:00 Lunch 14:00 15:30 Mini-projects (work in groups) 15:30 16:00 Coffee Break 16:00 17:00 Mini-projects (work in groups) 19:00 Dinner Wednesday 11 May start end topic 09:00 10:30 Mini-projects (work in groups) 10:30 11:00 Coffee Break 11:00 12:30 Mini-projects (work in groups) 12:30 14:00 Lunch 14:00 17:00 Recreational activity 19:00 Dinner Thursday 12 May start end topic 09:00 10:30 Mini-projects (work in groups) 10:30 11:00 Coffee Break 11:00 12:30 Keynote lecture by Dr. Joao Xavier from the Memorial Sloan Kettering Institute 12:30 14:00 Lunch 14:00 17:00 Mini-projects : prepare your presentations 19:00 Dinner Friday 13 May start end topic 09:00 09:45 Presentation of Mini-projects topic 1 09:45 10:30 Presentation of Mini-projects topic 2 10:30 11:00 Coffee Break + check out 11:00 11:45 Presentation of Mini-projects topic 3 11:45 12:30 Presentation of Mini-projects topic 4 12:30 13:30 Lunch 13:30 ~14:00 Conclusion & Wrap up","title":"Course schedule"},{"location":"course_schedule/#schedule","text":"ONGOING WORK Sunday 8 May (~18h00) start end topic ~18:00 Arrival & check-in 19:00 Dinner Monday 9 May start end topic 09:00 09:30 Introduction by the 3 organizing partners about the event 09:30 10:30 Lecture Topic 1 - Modeling antibiotic resistance evolution 10:30 11:00 Coffee Break 11:00 12:00 Lecture Topic 2 - Computational image analysis: transforming images into insights 12:15 13:45 Lunch 13:45 14:45 Lecture Topic 3 - Profiling and modeling the colorectal cancer microbiome 14:45 15:45 Lecture Topic 4 - Mathematical modeling of bacterial metabolism: diauxic growth of a population and syntrophic interactions in a consortium 15:45 16:15 Coffee break 16:15 17:00 Preparation for the mini-projects Tuesday 10 May start end topic 09:00 10:30 Mini-projects (work in groups) 10:30 11:00 Coffee Break 11:00 12:30 Mini-projects (work in groups) 12:30 14:00 Lunch 14:00 15:30 Mini-projects (work in groups) 15:30 16:00 Coffee Break 16:00 17:00 Mini-projects (work in groups) 19:00 Dinner Wednesday 11 May start end topic 09:00 10:30 Mini-projects (work in groups) 10:30 11:00 Coffee Break 11:00 12:30 Mini-projects (work in groups) 12:30 14:00 Lunch 14:00 17:00 Recreational activity 19:00 Dinner Thursday 12 May start end topic 09:00 10:30 Mini-projects (work in groups) 10:30 11:00 Coffee Break 11:00 12:30 Keynote lecture by Dr. Joao Xavier from the Memorial Sloan Kettering Institute 12:30 14:00 Lunch 14:00 17:00 Mini-projects : prepare your presentations 19:00 Dinner Friday 13 May start end topic 09:00 09:45 Presentation of Mini-projects topic 1 09:45 10:30 Presentation of Mini-projects topic 2 10:30 11:00 Coffee Break + check out 11:00 11:45 Presentation of Mini-projects topic 3 11:45 12:30 Presentation of Mini-projects topic 4 12:30 13:30 Lunch 13:30 ~14:00 Conclusion & Wrap up","title":"Schedule"},{"location":"precourse/","text":"","title":"Precourse preparations"},{"location":"project1/","text":"Project 1: Modeling antibiotic resistance evolution. Trainers: Fernanda Pinheiro , Group Leader in the Computational Biology Research Centre, Human Technopole , Milan; Leon Seeger , PhD student enrolled in the lab of Fernanda Pinheiro and Michael L\u00e4ssig - University of Cologne. Description: Bacterial growth under antibiotic challenge results from a complex interplay between antibiotic chemistry, nutrient conditions, bacterial physiology, and evolution. While antibiotics disrupt essential cellular processes of the wild-type susceptible background, they are less harmful to resistant bacteria. Resistant bacteria have multiple ways to counteract antibiotic action, including upregulation of its targets, alteration of membrane permeability, overexpression of efflux pumps, and enzymatic modification of antibiotics. How do different resistance mechanisms shape dosage-dependent bacterial growth? And what determines prevalent mechanisms of resistance evolution as a function of environmental conditions? In this course, we will build fitness models to characterize the dosage-dependent growth of antibiotic-resistant mutants. We will integrate the biophysics of drug action and antibiotic resistance mechanisms into coarse-grained models of cell metabolism to establish a mechanistic description of bacterial growth under challenge. We will then fit these models to existing data of dosage-response curves and map the conditions for the onset of different resistance mechanisms from the inferred biophysical parameters. Can we predict mechanisms of resistance evolution as a function of conditions? The lectures will expose the participants to theoretical developments (systems biology models of bacterial growth, metabolic fitness landscapes, evolutionary models), and numerical work will be done in MatLab or Python.","title":"Project 1"},{"location":"project2/","text":"Project 2: Computational image analysis: transforming images into insights. Trainers: Simon van Vliet , Project Leader, Biozentrum, University of Basel & NCCR AntiResist member; Alma Dal Co , associate professor, Departement of Computational Biology, University of Lausanne and NCCR Microbiomes member. Description: In natural environments, bacteria are often exposed to environments that change in time or space. Moreover, even in well-mixed clonal populations, bacteria can show dramatic variation in their growth, gene expression, and physiology. A main goal in current research is to study how these effects affect the growth and activity of microbial populations. To address these questions, many research groups are using in-vitro systems, such as agar pads and microfluidic devices, together with time-lapse microscopy to follow cell growth and gene expression in microbial populations at the single cell level. Although these experiments yield rich datasets, extracting biological insight from them can be challenging. In this course, participants will learn how to obtain biological insight from single-cell resolution, time-lapse microscopy data. We will cover all aspects of the image and data analysis workflow: from preprocessing, to segmenting and tracking cells, to feature extraction and statistical analysis. The participant will be introduced to a number of commonly used and state-of-the art tools, including imageJ, Ilastik, SciPy, and Deep Learning based workflows. The projects will focus on gaining hands-on experience: participants will work through a full image analysis workflow. In addition, we will give short lectures to introduce participants to alternative tools and other useful resources. At the end of the course, participants should be able to successfully analyze their own data using a variety of existing analysis tools. Requirements: Specific knowledge requirements for this project (besides basic knowledge of UNIX and R): Basic programming knowledge in Python / Matlab / R or similar Basic knowledge of statistical methods Some familiarity with Python is highly beneficial but not necessary. Participants without prior experience with Python are strongly recommended to follow a short online tutorial before the start of the course (instruction will be provided 3-4 weeks before start of course).","title":"Description"},{"location":"project3/","text":"Project 3: Profiling and modeling the colorectal cancer microbiome. Trainers: Alessio Milanese , Sunagawa Lab - Microbiome Research, ETH Zurich and SIB . NCCR Microbiomes member; Lukas Malfertheiner , Von Mering Lab - System Biology, University of Zurich and SIB . NCCR Microbiomes member; Description: Explore different cross-sectional metagenomic studies related to colorectal cancer (CRC), starting from taxonomic profiling to modeling by machine learning. Students will learn to work with metagenomic sequencing data and how to create taxonomic profiles from metagenomic samples using mOTUs (Milanese et al. 2019) . They will use R to explore properties typical for microbiome data (e.g., sparsity and sample size differences), use dimensionality reduction techniques and quantify within- and between-sample diversity. To explore associations between microbes and disease status, students will learn to use the SIAMCAT tool box (Wirbel et al. 2021) and develop a model for CRC classification based on taxonomic profiles. The project requires a basic understanding of the Unix command line and basic programming knowledge in R.","title":"Description"},{"location":"project4/","text":"Project 4: Mathematical modeling of bacterial metabolism: diauxic growth of a population and syntrophic interactions in a consortium Trainers: Hidde de Jong , Senior Research Scientist, INRIA Grenoble . Maaike Sangster , INRIA Grenoble . Description: We will step-by-step build simple ODE models of a metabolic network integrating regulation on both the metabolic and gene expression level, and investigate the effect of these layers of regulation on the network dynamics. The course will be structured around two examples: (i) carbon catabolite repression and diauxic growth in bacteria and (ii) synthrophic interactions in a consortium of two bacterial strains. All simulations will be carried out by means of Python.","title":"Project 4"},{"location":"project2/Home/","text":"Computational image analysis: transforming images into insights This wiki contains all information for the \u201cComputational image analysis: transforming images into insights\u201d part of the \u201cSpring School Bioinformatics and computational approaches in Microbiology\u201d organized by the NCCR AntiResist, NCCR Microbiomes, and the SIB PhD training network. Before the start of the course please follow all instructions on this page","title":"Computational image analysis: transforming images into insights"},{"location":"project2/Home/#computational-image-analysis-transforming-images-into-insights","text":"This wiki contains all information for the \u201cComputational image analysis: transforming images into insights\u201d part of the \u201cSpring School Bioinformatics and computational approaches in Microbiology\u201d organized by the NCCR AntiResist, NCCR Microbiomes, and the SIB PhD training network. Before the start of the course please follow all instructions on this page","title":"Computational image analysis: transforming images into insights"},{"location":"project2/Project-2A/","text":"Project 2A: Semi-automated processing using Fiji, Ilastik, and Python General note: this guide has been written assuming you use a Mac or Linux Command Line. Create project folders We first create a folder on your private computer for this course. Here we will assume it is ~/I2ICourse/ but you can use any folder (just change path variables accordingly). Open the command line and navigate to your home folder, then create a new folder called I2ICourse for the course: cd ~ mkdir I2ICourse Next create a folder for Project-2A ~/I2ICourse/Project2A/ : cd ~/I2ICourse/ mkdir Project2A And also make a folder for the processed data (output from all steps below): cd Project2A mkdir ProcessedData This should have created the following folder: ~/I2ICourse/Project2A/ProcessedData/ : Note: two useful terminal commands are: ls : show current folder content pwd : show path of current folder Download Data Here we will download the data via the command line. Navigate to the data folder: cd ~/I2ICourse/Project2A/ Download the data set and unzip it using: wget -O RawData.zip https://drive.switch.ch/index.php/s/VsWWiuaIctITWQl/download unzip RawData.zip You should now have a folder ~/I2ICourse/Project2A/RawData containing 3 tif files (hint: use ls to check!) We can delete the zip-file using: rm RawData.zip Alternative Download via browser If you have trouble downloading via command line, you can also use your browser: Open this link Click Download Unzip the compressed file inside your data folder. The data should now be located in ~/I2ICourse/Project2A/RawData Please rename the folder if needed Data preprocessing with Fiji We will first prepare the data in Fiji Merging & splitting color channels Before pre-processing we need to merge the color channels. Open the individual color images ( pos0-[c].tif , where c={r,g,p}) Image -> Color -> Merge Channels Make sure Create composite is selected Under C1 (red) select the [r] image Under C2 (green) select the [g] image Under C4 (grey) select the [p] image Save on disk as pos0-merged.tif use your processed data folder, e.g.: ~/I2ICourse/Project2A/ProcessedData/ Crop Image Make a rectangular selection around the area of interest Make sure that you make the area big enough to accommodate any remaining jitter. Go to Image -> Crop Save image as pos0-preproc-merged.tif use your processed data folder, e.g.: ~/I2ICourse/Project2A/ProcessedData/ Export data for segmentation First we split the image into separate color channels Image -> Color -> Split Channels Save the separate image channels under the name pos0-preproc-[c].tif In addition we need a combined image with the red and green channels. Use Merge Channels to combine the red and green channels (do not include phase!). Save on disk as pos0-preproc-rg.tif use your processed data folder, e.g.: ~/I2ICourse/Project2A/ProcessedData/ Aside: Other preprocessing steps During preprocessing you would often also do some other steps, for example: Registration: i.e. aligning images between frames to compensate for stage and sample drift Deconvolution: i.e. correcting for diffraction artifacts to make segmentation easier. Unfortunately we do not have time to go into this now, but please ask us during the breaks for more information! Segment with Ilastik We will give a brief live-demo of how to use Ilastik, please let us know when you are at this step, so that we can get the entire group together. You can find detailed instructions (and a movie) here . Most important steps (see also the pdf in the Project2A repository folder): Open Ilastik Select Pixel Classification workflow Save it in processed data folder as \u2018proj2A-ilastik\u2019 Go to Input Data Load the data of the red-green channel. Important: when adding the input data, you might have to change the axis order: double click on the axis order (e.g. zcyx ) and change to tcyx . Go to Feature Selection Select all features Go to Training Make two labels: Cells and BG Add sparse training points to indicate which pixels belong to cells and which to background Important: save your project frequently! Ilastik can crash! Use Live Update to visualize training Evaluate the result by checking Segmentation (Layer 1) You can use the Uncertainty to see where more training points need to be added Focus attention on pixels in between cells Once the segmentation looks good, check a few other frames and update training as needed, until it looks good for all frames. Go to Prediction Export See details here In Export Settings select Probabilities in the source field. Open Choose Export Image Setting and select hdf5 format. Then click Export All Select as output folder ~/I2ICourse/Project2A/ProcessedData/ The output should be stored under the name [input_file_name]_Probabilities.h5 , i.e. pos0_preproc-rg_Probabilities.h5 . Post-process with Python We will now switch to the cloud computers for the next steps. Create project folders on cloud computer On the cloud computer, we have to recreate the project folder: cd ~ mkdir I2ICourse We also make some extra folders for Project2A: cd ~/I2ICourse/ mkdir Project2A cd Project2A mkdir ProcessedData Download project code Navigate to the project folder and use the git clone command to download the course code: cd ~/I2ICourse/ git clone https://github.com/sib-swiss/spring_school_bioinformatics_microbiology.git This will create the folder ~/I2ICourse/spring_school_bioinformatics_microbiology/ which contains all the Jupyter notebooks as well as the other course files Transfer the data Then we have to transfer the data from your local computer to the cloud computer First compress the ~/I2ICourse/Project2A/ProcessedData folder on your local computer into a zip-file Upload this zip file to a cloud drive Create a public share link and copy the address cd ~/I2ICourse/Project2A/ProcessedData wget -O data.zip public_link_to_your_zip_file unzip -j data.zip Launch Jupyter Labs Next navigate to the project folder, activate the conda environment, and launch Jupyter Labs: cd ~/I2ICourse/ conda activate i2i_env jupyter lab In Jupyter Labs, navigate to spring_school_bioinformatics_microbiology/projects/project2/Project2A/ Then open the post_process_segementation.ipynb notebook Now run the notebook, see here for instructions on Jupyter Labs","title":"Project 2A"},{"location":"project2/Project-2A/#project-2a-semi-automated-processing-using-fiji-ilastik-and-python","text":"General note: this guide has been written assuming you use a Mac or Linux Command Line.","title":"Project 2A: Semi-automated processing using Fiji, Ilastik, and Python"},{"location":"project2/Project-2A/#create-project-folders","text":"We first create a folder on your private computer for this course. Here we will assume it is ~/I2ICourse/ but you can use any folder (just change path variables accordingly). Open the command line and navigate to your home folder, then create a new folder called I2ICourse for the course: cd ~ mkdir I2ICourse Next create a folder for Project-2A ~/I2ICourse/Project2A/ : cd ~/I2ICourse/ mkdir Project2A And also make a folder for the processed data (output from all steps below): cd Project2A mkdir ProcessedData This should have created the following folder: ~/I2ICourse/Project2A/ProcessedData/ : Note: two useful terminal commands are: ls : show current folder content pwd : show path of current folder","title":"Create project folders"},{"location":"project2/Project-2A/#download-data","text":"Here we will download the data via the command line. Navigate to the data folder: cd ~/I2ICourse/Project2A/ Download the data set and unzip it using: wget -O RawData.zip https://drive.switch.ch/index.php/s/VsWWiuaIctITWQl/download unzip RawData.zip You should now have a folder ~/I2ICourse/Project2A/RawData containing 3 tif files (hint: use ls to check!) We can delete the zip-file using: rm RawData.zip","title":"Download Data"},{"location":"project2/Project-2A/#alternative-download-via-browser","text":"If you have trouble downloading via command line, you can also use your browser: Open this link Click Download Unzip the compressed file inside your data folder. The data should now be located in ~/I2ICourse/Project2A/RawData Please rename the folder if needed","title":"Alternative Download via browser"},{"location":"project2/Project-2A/#data-preprocessing-with-fiji","text":"We will first prepare the data in Fiji","title":"Data preprocessing with Fiji"},{"location":"project2/Project-2A/#merging-splitting-color-channels","text":"Before pre-processing we need to merge the color channels. Open the individual color images ( pos0-[c].tif , where c={r,g,p}) Image -> Color -> Merge Channels Make sure Create composite is selected Under C1 (red) select the [r] image Under C2 (green) select the [g] image Under C4 (grey) select the [p] image Save on disk as pos0-merged.tif use your processed data folder, e.g.: ~/I2ICourse/Project2A/ProcessedData/","title":"Merging &amp; splitting color channels"},{"location":"project2/Project-2A/#crop-image","text":"Make a rectangular selection around the area of interest Make sure that you make the area big enough to accommodate any remaining jitter. Go to Image -> Crop Save image as pos0-preproc-merged.tif use your processed data folder, e.g.: ~/I2ICourse/Project2A/ProcessedData/","title":"Crop Image"},{"location":"project2/Project-2A/#export-data-for-segmentation","text":"First we split the image into separate color channels Image -> Color -> Split Channels Save the separate image channels under the name pos0-preproc-[c].tif In addition we need a combined image with the red and green channels. Use Merge Channels to combine the red and green channels (do not include phase!). Save on disk as pos0-preproc-rg.tif use your processed data folder, e.g.: ~/I2ICourse/Project2A/ProcessedData/","title":"Export data for segmentation"},{"location":"project2/Project-2A/#aside-other-preprocessing-steps","text":"During preprocessing you would often also do some other steps, for example: Registration: i.e. aligning images between frames to compensate for stage and sample drift Deconvolution: i.e. correcting for diffraction artifacts to make segmentation easier. Unfortunately we do not have time to go into this now, but please ask us during the breaks for more information!","title":"Aside: Other preprocessing steps"},{"location":"project2/Project-2A/#segment-with-ilastik","text":"We will give a brief live-demo of how to use Ilastik, please let us know when you are at this step, so that we can get the entire group together. You can find detailed instructions (and a movie) here . Most important steps (see also the pdf in the Project2A repository folder): Open Ilastik Select Pixel Classification workflow Save it in processed data folder as \u2018proj2A-ilastik\u2019 Go to Input Data Load the data of the red-green channel. Important: when adding the input data, you might have to change the axis order: double click on the axis order (e.g. zcyx ) and change to tcyx . Go to Feature Selection Select all features Go to Training Make two labels: Cells and BG Add sparse training points to indicate which pixels belong to cells and which to background Important: save your project frequently! Ilastik can crash! Use Live Update to visualize training Evaluate the result by checking Segmentation (Layer 1) You can use the Uncertainty to see where more training points need to be added Focus attention on pixels in between cells Once the segmentation looks good, check a few other frames and update training as needed, until it looks good for all frames. Go to Prediction Export See details here In Export Settings select Probabilities in the source field. Open Choose Export Image Setting and select hdf5 format. Then click Export All Select as output folder ~/I2ICourse/Project2A/ProcessedData/ The output should be stored under the name [input_file_name]_Probabilities.h5 , i.e. pos0_preproc-rg_Probabilities.h5 .","title":"Segment with Ilastik"},{"location":"project2/Project-2A/#post-process-with-python","text":"We will now switch to the cloud computers for the next steps.","title":"Post-process with Python"},{"location":"project2/Project-2A/#create-project-folders-on-cloud-computer","text":"On the cloud computer, we have to recreate the project folder: cd ~ mkdir I2ICourse We also make some extra folders for Project2A: cd ~/I2ICourse/ mkdir Project2A cd Project2A mkdir ProcessedData","title":"Create project folders on cloud computer"},{"location":"project2/Project-2A/#download-project-code","text":"Navigate to the project folder and use the git clone command to download the course code: cd ~/I2ICourse/ git clone https://github.com/sib-swiss/spring_school_bioinformatics_microbiology.git This will create the folder ~/I2ICourse/spring_school_bioinformatics_microbiology/ which contains all the Jupyter notebooks as well as the other course files","title":"Download project code"},{"location":"project2/Project-2A/#transfer-the-data","text":"Then we have to transfer the data from your local computer to the cloud computer First compress the ~/I2ICourse/Project2A/ProcessedData folder on your local computer into a zip-file Upload this zip file to a cloud drive Create a public share link and copy the address cd ~/I2ICourse/Project2A/ProcessedData wget -O data.zip public_link_to_your_zip_file unzip -j data.zip","title":"Transfer the data"},{"location":"project2/Project-2A/#launch-jupyter-labs","text":"Next navigate to the project folder, activate the conda environment, and launch Jupyter Labs: cd ~/I2ICourse/ conda activate i2i_env jupyter lab In Jupyter Labs, navigate to spring_school_bioinformatics_microbiology/projects/project2/Project2A/ Then open the post_process_segementation.ipynb notebook Now run the notebook, see here for instructions on Jupyter Labs","title":"Launch Jupyter Labs"},{"location":"project2/Project-2B/","text":"Segmentation and Tracking 2D Data with Delta2.0 Delta 2.0 is a Deep Learning based workflow that can segment and track 1D (mother machine) and 2D (family machine and agar pads) data. It uses two consecutive U-Net networks to first segment and then track cells. The pipeline is described in this publication . Detailed instruction can be found here Get started We will work on the cloud computers for the full project On the cloud computer navigate to the project folder, activate the conda environment, and launch Jupyter Labs: cd ~/I2ICourse/ conda activate i2i_env jupyter lab In Jupyter Labs, navigate to spring_school_bioinformatics_microbiology/projects/project2/Project2B/ Then follow the steps below. Download test data Run the 0_download_model_delta notebook to download the pre-trained network and data (note this may take some time, best to run this over a break!) Run the pipeline Work trough the 1_run_pipeline_delta notebook to see how the Delta2 pipeline works. Note: processing speeds on CPU are very slow so use a CUDA compatible GPU based computer whenever possible. Note: we also provided some instructions on how to use Delta on the Scicore cluster of University Basel [see scicore.md ], to use Delta on clusters of other institutions, please contact your local cluster managers. You can also try-out Delta on Google CoLabs . Analyze the results Work trough the 2_post_processing_delta notebook. Analyze the data Once you have the data analyzed, try to extract biological insight from it. Discuss with your tutor what question you could address. For this step on we encourage people to team-up in pairs/small-groups and work together. You can use the 3_explore_data_delta notebook as a starting point. Note on data The dataset we will work with consists of a time-lapse data of a micro-colony of E. coli cells growing on LB agar pads. Images were taken every 5min. We have two channels: phase contrast and GFP. The GFP signal comes from a transcriptional reporter for Colicin Ib, a bacteriocin that is regulated by SOS-stress response. More info on the data can be found here .","title":"Project 2B"},{"location":"project2/Project-2B/#segmentation-and-tracking-2d-data-with-delta20","text":"Delta 2.0 is a Deep Learning based workflow that can segment and track 1D (mother machine) and 2D (family machine and agar pads) data. It uses two consecutive U-Net networks to first segment and then track cells. The pipeline is described in this publication . Detailed instruction can be found here","title":"Segmentation and Tracking 2D Data with Delta2.0"},{"location":"project2/Project-2B/#get-started","text":"We will work on the cloud computers for the full project On the cloud computer navigate to the project folder, activate the conda environment, and launch Jupyter Labs: cd ~/I2ICourse/ conda activate i2i_env jupyter lab In Jupyter Labs, navigate to spring_school_bioinformatics_microbiology/projects/project2/Project2B/ Then follow the steps below.","title":"Get started"},{"location":"project2/Project-2B/#download-test-data","text":"Run the 0_download_model_delta notebook to download the pre-trained network and data (note this may take some time, best to run this over a break!)","title":"Download test data"},{"location":"project2/Project-2B/#run-the-pipeline","text":"Work trough the 1_run_pipeline_delta notebook to see how the Delta2 pipeline works. Note: processing speeds on CPU are very slow so use a CUDA compatible GPU based computer whenever possible. Note: we also provided some instructions on how to use Delta on the Scicore cluster of University Basel [see scicore.md ], to use Delta on clusters of other institutions, please contact your local cluster managers. You can also try-out Delta on Google CoLabs .","title":"Run the pipeline"},{"location":"project2/Project-2B/#analyze-the-results","text":"Work trough the 2_post_processing_delta notebook.","title":"Analyze the results"},{"location":"project2/Project-2B/#analyze-the-data","text":"Once you have the data analyzed, try to extract biological insight from it. Discuss with your tutor what question you could address. For this step on we encourage people to team-up in pairs/small-groups and work together. You can use the 3_explore_data_delta notebook as a starting point.","title":"Analyze the data"},{"location":"project2/Project-2B/#note-on-data","text":"The dataset we will work with consists of a time-lapse data of a micro-colony of E. coli cells growing on LB agar pads. Images were taken every 5min. We have two channels: phase contrast and GFP. The GFP signal comes from a transcriptional reporter for Colicin Ib, a bacteriocin that is regulated by SOS-stress response. More info on the data can be found here .","title":"Note on data"},{"location":"project2/Project2_Overview/","text":"Overview of Project 2 The course consists of three main parts: In the first part everyone will work on the same data (Project 2A). We will use a semi-automated workflow to segment time-lapse movie of 2D microfluidic flowcells and analyze how the frequency of two interacting cell types changes over time. In this part everyone works on independently. In the second part we will split the group into two. Half the group will use Delta2.0 to segment and track micro-colonies growing on agar pads (Project 2B). The other half will use BACMMAN to segment and track cells growing in 1D mother-machine microfluidic flowcells (Project 2C). In this part everyone works on independently. In the third part we will use data we obtained in the second part to try to answer biological questions. In this part you are encouraged to team up in pairs and work together.","title":"Overview"},{"location":"project2/Project2_Overview/#overview-of-project-2","text":"The course consists of three main parts: In the first part everyone will work on the same data (Project 2A). We will use a semi-automated workflow to segment time-lapse movie of 2D microfluidic flowcells and analyze how the frequency of two interacting cell types changes over time. In this part everyone works on independently. In the second part we will split the group into two. Half the group will use Delta2.0 to segment and track micro-colonies growing on agar pads (Project 2B). The other half will use BACMMAN to segment and track cells growing in 1D mother-machine microfluidic flowcells (Project 2C). In this part everyone works on independently. In the third part we will use data we obtained in the second part to try to answer biological questions. In this part you are encouraged to team up in pairs and work together.","title":"Overview of Project 2"},{"location":"project2/Project2_Preparation/","text":"Preparation before start of course To get started quickly during the course, we ask you to prepare a few things. Optional: Python Tutorial For those with little or no Python experience: we recommend you have a look at the following two notebooks that very briefly introduced the most important concepts and syntax: General python introduction (made available by Oliver Meacock , University of Lausanne) Short intro to Pandas dataframes (made available by Google) Setup Cloud Drive We will need to transfer data between our local computers and cloud workstations, for this you need access to a cloud drive (e.g. Dropbox, Google Drive, Switch Drive, etc.) with at least 3GB of free space. For those based at a Swiss institution: you can setup a free account at SwitchDrive which gives you 100GB of space. Install Software During the course we will use a number of software packages, we ask you to install a few of these before the start of the course. In case you run into any problems please do not hesitate to contact Simon van Vliet (preferentially via Slack). We will use the following software: Ilastik -> Please install before start of course following instructions below BACMMAN (Fiji-ImageJ) -> Please install before start of course following instructions below Python (Anaconda) -> No need to install, we will use cloud-based computers to run our Python code For completeness we also include instructions on how to install Python/Anaconda on your own computers below, however you can ignore these for now. Installation Instructions Ilastik Ilastik is a flexible GUI based application that offers several machine learning based workflow for image analysis. We will use it for supervised pixel segmentation. We will use Ilastik beta version 1.4.0b21 (or newer) in the course Download it here Expand the archive and move the Ilastik application to your application folder Bacmman BACMMAN (BACteria in Mother Machine Analyzer) is a ImageJ plugin that offers a fully automated workflow to analyze mother machine data. Install Fiji Download here On Mac/Linux: copy Fiji app to application folder (or other folder of choice) Note: OSX will give a security warning, please go into settings to give permission to launch Fiji On Windows: copy Fiji app to a folder in your user space e.g. C:\\Users\\[your name]\\ImageJ.app Already have Fiji installed? Please install a fresh copy of Fiji nonetheless! You can have multiple copies of Fiji on your computer, simply rename the new copy of Fiji to e.g. Fiji_Bacmman. Update Fiji Start Fiji Update Fiji with default update sites (ImageJ / Fiji / Java 8): Go to Help -> Update In ImageJ Updater window click on Apply Changes Restart Fiji Repeat until message \u2018Your ImageJ is up to date!\u2019 message appears Install Bacmman Go to Help -> Update In ImageJ Updater window click on Manage update sites In the list select (add a tick to tick box) the following extra update sites: BACMMAN ( https://sites.imagej.net/BACMMAN/ ) BACMMAN-DL ( https://sites.imagej.net/BACMMAN-DL/ ) ImageScience ( https://sites.imagej.net/ImageScience/ ) Click Close In ImageJ Updater window click on Apply Changes Restart Fiji Optional: Install Mac OSX terminal packages Although Mac OSX has a number of Terminal packages included by default (e.g. git), other need to be installed manually. Homebrew is a convenient package manager that allows you to obtain these packages. To install, follow these instructions: install OS X command line tools using: xcode-select --install Install Homebrew package manager using: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" You will be asked for your admin password! Install wget using: brew install wget Optional: Download jupyter notebooks for course Note: during the course we will use cloud-based computers for this step, so you do not have to do this on your private machine. These instructions are provided for the sake of completeness in case you want to continue working on the project after the course. We need to obtain the code we need for the course by cloning the Git repository Open the command line and navigate to your home folder, then create a new folder called I2ICourse for the course: cd ~ mkdir I2ICourse Next navigate to this new folder and use the git clone command to download the course code: cd ~/I2ICourse/ git clone https://github.com/sib-swiss/spring_school_bioinformatics_microbiology.git This will create the folder ~/I2ICourse/spring_school_bioinformatics_microbiology/ which contains all the Jupyter notebooks as well as the other course files Optional: Install Conda (Python) Note: during the course we will use cloud-based computers for this step, so you do not have to do this on your private machine. These instructions are provided for the sake of completeness in case you want to continue working on the project after the course. Note: all our code has been tested with Conda version 4.11 and python version 3.9 Install Anaconda Important: if you have an older version of Anaconda installed (Anaconda2 or below) please first remove it and re-install the latest Anaconda3 version! Install Anaconda following the provided instruction. If you already have an Anaconda3 (or Mini Conda) installation, please update to latest version using: conda update conda conda update --all Optionally: you can update to latest python version (3.9), but this is not needed (we will install python 3.9 in a virtual environment below). To update use: conda install python = 3 .9 Note: alternatively you can install MiniConda, this is a minimal conda install that takes up much less space than Anaconda, but provides identical functionality. Follow instructions here . Optional: Install Mamba The conda package manager can be rather slow at times. Luckily there is a newer alternative to conda, called mamba . mamba and conda work interchangeably, and use same syntax: just replace conda with mamba . One exception: activating and deactivating environments still has to be done with the conda command. Install mamba using conda install mamba -n base -c conda-forge Create new Conda Environment It is best practice to use a separate conda environment for each project, this way you avoid conflicts in package requirements. You can create a new conda environment with the following command: conda create --name [ environment_name ] [ list of packages to install ] Alternatively you can create a new environment from a .yml environment file that specifies all packages: conda env create -f environment.yml We now create the environment for the course, using: conda env create -f i2i_env.yml Note: you can also use mamba for this step in case you installed it before. Optional: Test Conda environment Note: during the course we will use cloud-based computers for this step, so you do not have to do this on your private machine. These instructions are provided for the sake of completeness in case you want to continue working on the project after the course. First navigate to your project folder cd ~/I2ICourse/ Then activate the conda environment: conda activate i2i_env Next open jupyter-labs: jupyter lab In Jupyter labs, navigate to /I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/ Then open the test_notebook.ipynb Now run the notebook (see here for instructions ) Notes Trouble-shooting In case of persistent problems, try deleting your existing Conda installation and install the latest version from link above. Note: make sure to backup essential conda environments before doing this! Alternatives You can use Jupyter Notebook instead of Jupyter Lab. Both have same functionality, but Jupyter Lab has a bit nicer interface. To install: replace jupyterlab with notebook To open: replace jupyter-lab with jupyter notebook Visual Studio Code (VS Code) is a cross-platform app that you can use to run Jupyter Notebooks. It has some added advantage compared to Jupyter Notebook / Jupyter Lab: it has a nice and fully customizable interface, a great build-in debugger, and offers several useful extensions such as: Jupyter (required to Jupyter notebooks) Markdown All in One (Markdown support) Python Gitlens (full Git integration) Code Spell Checker (intelligent spell checking) and many others","title":"Preparation"},{"location":"project2/Project2_Preparation/#preparation-before-start-of-course","text":"To get started quickly during the course, we ask you to prepare a few things.","title":"Preparation before start of course"},{"location":"project2/Project2_Preparation/#optional-python-tutorial","text":"For those with little or no Python experience: we recommend you have a look at the following two notebooks that very briefly introduced the most important concepts and syntax: General python introduction (made available by Oliver Meacock , University of Lausanne) Short intro to Pandas dataframes (made available by Google)","title":"Optional: Python Tutorial"},{"location":"project2/Project2_Preparation/#setup-cloud-drive","text":"We will need to transfer data between our local computers and cloud workstations, for this you need access to a cloud drive (e.g. Dropbox, Google Drive, Switch Drive, etc.) with at least 3GB of free space. For those based at a Swiss institution: you can setup a free account at SwitchDrive which gives you 100GB of space.","title":"Setup Cloud Drive"},{"location":"project2/Project2_Preparation/#install-software","text":"During the course we will use a number of software packages, we ask you to install a few of these before the start of the course. In case you run into any problems please do not hesitate to contact Simon van Vliet (preferentially via Slack). We will use the following software: Ilastik -> Please install before start of course following instructions below BACMMAN (Fiji-ImageJ) -> Please install before start of course following instructions below Python (Anaconda) -> No need to install, we will use cloud-based computers to run our Python code For completeness we also include instructions on how to install Python/Anaconda on your own computers below, however you can ignore these for now.","title":"Install Software"},{"location":"project2/Project2_Preparation/#installation-instructions","text":"","title":"Installation Instructions"},{"location":"project2/Project2_Preparation/#ilastik","text":"Ilastik is a flexible GUI based application that offers several machine learning based workflow for image analysis. We will use it for supervised pixel segmentation. We will use Ilastik beta version 1.4.0b21 (or newer) in the course Download it here Expand the archive and move the Ilastik application to your application folder","title":"Ilastik"},{"location":"project2/Project2_Preparation/#bacmman","text":"BACMMAN (BACteria in Mother Machine Analyzer) is a ImageJ plugin that offers a fully automated workflow to analyze mother machine data.","title":"Bacmman"},{"location":"project2/Project2_Preparation/#install-fiji","text":"Download here On Mac/Linux: copy Fiji app to application folder (or other folder of choice) Note: OSX will give a security warning, please go into settings to give permission to launch Fiji On Windows: copy Fiji app to a folder in your user space e.g. C:\\Users\\[your name]\\ImageJ.app","title":"Install Fiji"},{"location":"project2/Project2_Preparation/#already-have-fiji-installed","text":"Please install a fresh copy of Fiji nonetheless! You can have multiple copies of Fiji on your computer, simply rename the new copy of Fiji to e.g. Fiji_Bacmman.","title":"Already have Fiji installed?"},{"location":"project2/Project2_Preparation/#update-fiji","text":"Start Fiji Update Fiji with default update sites (ImageJ / Fiji / Java 8): Go to Help -> Update In ImageJ Updater window click on Apply Changes Restart Fiji Repeat until message \u2018Your ImageJ is up to date!\u2019 message appears","title":"Update Fiji"},{"location":"project2/Project2_Preparation/#install-bacmman","text":"Go to Help -> Update In ImageJ Updater window click on Manage update sites In the list select (add a tick to tick box) the following extra update sites: BACMMAN ( https://sites.imagej.net/BACMMAN/ ) BACMMAN-DL ( https://sites.imagej.net/BACMMAN-DL/ ) ImageScience ( https://sites.imagej.net/ImageScience/ ) Click Close In ImageJ Updater window click on Apply Changes Restart Fiji","title":"Install Bacmman"},{"location":"project2/Project2_Preparation/#optional-install-mac-osx-terminal-packages","text":"Although Mac OSX has a number of Terminal packages included by default (e.g. git), other need to be installed manually. Homebrew is a convenient package manager that allows you to obtain these packages. To install, follow these instructions: install OS X command line tools using: xcode-select --install Install Homebrew package manager using: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" You will be asked for your admin password! Install wget using: brew install wget","title":"Optional: Install Mac OSX terminal packages"},{"location":"project2/Project2_Preparation/#optional-download-jupyter-notebooks-for-course","text":"Note: during the course we will use cloud-based computers for this step, so you do not have to do this on your private machine. These instructions are provided for the sake of completeness in case you want to continue working on the project after the course. We need to obtain the code we need for the course by cloning the Git repository Open the command line and navigate to your home folder, then create a new folder called I2ICourse for the course: cd ~ mkdir I2ICourse Next navigate to this new folder and use the git clone command to download the course code: cd ~/I2ICourse/ git clone https://github.com/sib-swiss/spring_school_bioinformatics_microbiology.git This will create the folder ~/I2ICourse/spring_school_bioinformatics_microbiology/ which contains all the Jupyter notebooks as well as the other course files","title":"Optional: Download jupyter notebooks for course"},{"location":"project2/Project2_Preparation/#optional-install-conda-python","text":"Note: during the course we will use cloud-based computers for this step, so you do not have to do this on your private machine. These instructions are provided for the sake of completeness in case you want to continue working on the project after the course. Note: all our code has been tested with Conda version 4.11 and python version 3.9","title":"Optional: Install Conda (Python)"},{"location":"project2/Project2_Preparation/#install-anaconda","text":"Important: if you have an older version of Anaconda installed (Anaconda2 or below) please first remove it and re-install the latest Anaconda3 version! Install Anaconda following the provided instruction. If you already have an Anaconda3 (or Mini Conda) installation, please update to latest version using: conda update conda conda update --all Optionally: you can update to latest python version (3.9), but this is not needed (we will install python 3.9 in a virtual environment below). To update use: conda install python = 3 .9 Note: alternatively you can install MiniConda, this is a minimal conda install that takes up much less space than Anaconda, but provides identical functionality. Follow instructions here .","title":"Install Anaconda"},{"location":"project2/Project2_Preparation/#optional-install-mamba","text":"The conda package manager can be rather slow at times. Luckily there is a newer alternative to conda, called mamba . mamba and conda work interchangeably, and use same syntax: just replace conda with mamba . One exception: activating and deactivating environments still has to be done with the conda command. Install mamba using conda install mamba -n base -c conda-forge","title":"Optional: Install Mamba"},{"location":"project2/Project2_Preparation/#create-new-conda-environment","text":"It is best practice to use a separate conda environment for each project, this way you avoid conflicts in package requirements. You can create a new conda environment with the following command: conda create --name [ environment_name ] [ list of packages to install ] Alternatively you can create a new environment from a .yml environment file that specifies all packages: conda env create -f environment.yml We now create the environment for the course, using: conda env create -f i2i_env.yml Note: you can also use mamba for this step in case you installed it before.","title":"Create new Conda Environment"},{"location":"project2/Project2_Preparation/#optional-test-conda-environment","text":"Note: during the course we will use cloud-based computers for this step, so you do not have to do this on your private machine. These instructions are provided for the sake of completeness in case you want to continue working on the project after the course. First navigate to your project folder cd ~/I2ICourse/ Then activate the conda environment: conda activate i2i_env Next open jupyter-labs: jupyter lab In Jupyter labs, navigate to /I2ICourse/spring_school_bioinformatics_microbiology/projects/project2/ Then open the test_notebook.ipynb Now run the notebook (see here for instructions )","title":"Optional: Test Conda environment"},{"location":"project2/Project2_Preparation/#notes","text":"","title":"Notes"},{"location":"project2/Project2_Preparation/#trouble-shooting","text":"In case of persistent problems, try deleting your existing Conda installation and install the latest version from link above. Note: make sure to backup essential conda environments before doing this!","title":"Trouble-shooting"},{"location":"project2/Project2_Preparation/#alternatives","text":"You can use Jupyter Notebook instead of Jupyter Lab. Both have same functionality, but Jupyter Lab has a bit nicer interface. To install: replace jupyterlab with notebook To open: replace jupyter-lab with jupyter notebook Visual Studio Code (VS Code) is a cross-platform app that you can use to run Jupyter Notebooks. It has some added advantage compared to Jupyter Notebook / Jupyter Lab: it has a nice and fully customizable interface, a great build-in debugger, and offers several useful extensions such as: Jupyter (required to Jupyter notebooks) Markdown All in One (Markdown support) Python Gitlens (full Git integration) Code Spell Checker (intelligent spell checking) and many others","title":"Alternatives"},{"location":"project2/project-2C/","text":"Segmentation and Tracking Mother Machine Data with Bacmman & DistNet Bacmman is a ImageJ plugin for analyzing mother machine data. All interactions with the software are via a GUI making it relatively user-friendly (though with a bit of a steep learning curve). At the backend Bacmman uses a state-of-the-art deep learning network to track and segment cells. Download Data Important: the dataset is 5GB big, so start download at latest on Tuesday morning! cd I2ICourse mkdir Project2C cd Project2C wget -O RawData.zip https://drive.switch.ch/index.php/s/nwwP9spbricnFTW/download unzip -j RawData.zip Check the folder content (it should contain 2 tiff files). The remove the zip file with rm RawData.zip Getting started Note: parts of this tutorial have been adapted from this Wiki page of Jean Ollion. Bacmman is described extensively in this Nature Protocols article , however note that some parts are outdated. Specifically, the protocol uses the older, classical algorithm to track and segment cells. The parts that describe the GUI are still very useful though. More up-to-date info can be found on this wiki . The Distnet Deep Learning network is described in this publication . Open Bacmman Open Fiji Go to Plugins -> Bacmman -> Bacteria in Mother Machine Analyzer Create a Dataset Set working directory When using Bacmman for the first time choose a working directory. Right-click on the panel below Working Directory and select Choose Local Folder make a new folder in ~/I2ICourse/Project2C/Bacmman/ and select this one Create new data set Click on Dataset menu and select New Dataset from Online Library Select dataset1_distnet When asked name it Project2C Note: after re-opening Bacmann you can re-open the dataset by double clicking on its name in the Dataset field Adapt configuration file Go to Configuration tab Right click on Import Method and select One file per Channel & Position The expand the Pre-Processing Template Go to Time Step and set to 7.5 (right click on value to change it). This is the time-interval, in minutes, between frames. Click on Dataset menu and select Save configuration changes Add Image Data Go to Home tab Right click in Positions fields and select Import/re-link images Select the folder containing the Tiff Files: ~/I2ICourse/Project2C/RawData You should now see a list iof tiff images. You can inspect the data by right clicking on an image and select Open Input images . Define Pre-processing Configuration Preprocessing steps Bacmman needs to do some pre-processing before the Distnet algorithm can segment cells. Specifically: Images should be cropped to only contain channels Images should be rotated if needed such that channels are vertically aligned Images should be flipped if needed such that channels points down Bacmman provides automated algorithms to do this, these can be adapted to fit your images. Unfortunately this does not always work. In fact, for our data we have been unable to find settings that work. However, we will still show you how to change the automated steps before skipping to manual pre-processing. Test automated pre-processing pipeline Go to Configuration Test Tab In Step select Pre-Processing For speed lets only test a few frames: right click on Frame Range and set range from 0 to 5 (you can reduce this further if needed) Let\u2019s try the AutoFlipY step that flips the microchannels. Right click on this step and select Test Transformation You can see the result looks bad: our channels were flipped even though they should not have (they should point down). Now try to find settings that work. Important spend max 5min on this!** Hint: you can right click on almost anything in Bacmmann to see and change settings. Hint: adapt the micro-channel height (doesn\u2019t have to be real length) Hint: if that does not work try changing the method It can be hard to find good settings, and some pre-processing might need to be done by hand. To remove an automated step, right click on it and select remove . You can add new modules. In the top right list are all Available Modules. To add one, right click on Pre-Processing Pipeline , this adds a new Transformation. Select this one, and then click on the desired module in the Available Modules list. Now change the config to the one shown in this screenshot: During testing this worked for us, please check! Then click on Copy to all position and copy to template Save the configuration via the Dataset menu Aside: Setup manual pre-processing pipeline Do not do this now, we use automated pipeline setup above! Sometimes finding automatic settings might be too hard, in that case you can then use manual cropping and flipping as shown in this screen shot: With the simple crop option, you need to set the crop box manually for each position. Important: for channels that point up, first add a Flip step. This should be done before the crop (see screenshot above). Test the SimpleCrop first with the default settings, this opens the image without cropping. Now you can draw a bounding box around the channels. Make sure to exclude the exits of the channels where there is a strong phase artifact, at the top keep a bit of space (10-20 pixels) to accommodate stage jitter (see screenshot). Write down the crop-box size and location and enter the numbers in the settings. Repeat this for all positions. Keep the full width of the image (do not change x-settings) and only change the y-values (see screenshot) Run pre-processing pipeline To run pre-processing Select all positions Select the task: Pre-Processing Choose the menu command Run > Run Selected Tasks This step will take a while. To visualize the pre-processed images right-click on the position and choose Open Pre-Processed Images Configure processing pipeline The main processing pipeline does not need much configuration: the deep learning network takes care of almost everything. There are a couple things that we need to do though. Download Model Weights As DiSTNet is a deep-learning based method, it requires trained weights of the model. To download them (only needed first time you run Bacmman) Go to the Configuration Test tab In the Step panel select Processing In Object Class select Bacteria Unfold the parameters Tracker > Model > Tensorflow Model . The sub-parameter Model File appears in red if the model weights are not there. However it is possible to download them directly from BACMMAN. Right-click on Tensorflow Model and choose Download Model . The model weights will be downloaded at the path selected in the Model File parameter, that should not appear in red anymore after the download. Adapt channel width Go to the Configuration Test tab In the Step panel select Processing In Object Class select microchannels Set the channel width (in pixels) to the range seen in the data Run tracking and segmentation Go back to the Home tab Select the objects Microchannels and Bacteria at the same time Select the task: Segmentation & Tracking Choose the menu command Run > Run Selected Tasks Check micro-channel segmentation and tracking To visualize the result of microchannel segmentation and tracking: Go to the Data Browsing tab Right-click on the position and choose Open Hyperstack > Microchannels The pre-processed images will open as a interactive hyperstack (multi-channel & multi-frames image stack), on which microchannels can be selected. To display all segmented microchannels object use the shortcut crtl + A To display all microchannels tracks use the shortcut crtl + Q . Tracks will be displayed as colored contours, each color corresponding to one track. Note that the shortcut are available from the menu Help > Display Shortcut table and that a shortcut preset adapted for QWERTY keyboards can be chosen from the menu Help > Shortcut Presets Check bacterial segmentation and tracking To visualize the result of bacterial segmentation and tracking: Go to the Data Browsing tab Right-click on the position and choose Open Hyperstack > Bacteria The pre-processed images will open as a interactive hyperstack (multi-channel & multi-frames image stack), on which bacteria can be selected. To display all segmented bacteria object use the shortcut crtl + A To display all bacteria tracks use the shortcut crtl + Q . Tracks will be displayed as colored contours, each color corresponding to one track. Note that the shortcut are available from the menu Help > Display Shortcut table and that a shortcut preset adapted for QWERTY keyboards can be chosen from the menu Help > Shortcut Presets Another good way to visualize tracking is to use the Kymograph view: In the Segmentation & Tracking Results area, click on the arrow next to Position #0 to expand the list of micro channels. Right-click on a micro-channel and choose Open Kymograph > Bacteria The resulting image shows a concatenation of the same micro-channel for all time points To display all segmented bacteria object use the shortcut crtl + A To display all bacteria tracks use the shortcut crtl + Q . Tracks will be displayed as colored lines connecting neighboring time points. Export the data Go to the Home tab Select the object Bacteria Select the tasks Measurements & Extract Measurements Choose the menu command Run > Run Selected Tasks Post-process with Python We will now switch to the cloud computers for the next steps. Create project folders on cloud computer On the cloud computer, we have to make the project folders: cd ~/I2ICourse/ mkdir Project2C cd Project2C mkdir ProcessedData Transfer the data Then we have to transfer the data from your local computer to the cloud computer Upload the output file of Bacmann to a cloud drive, this file is located in: Create a public share link and copy the address cd ~/I2ICourse/Project2C/ProcessedData wget -O data.zip public_link_to_your_zip_file unzip -j data.zip Launch Jupyter Labs Next navigate to the project folder, activate the conda environment, and launch Jupyter Labs: cd ~/I2ICourse/ conda activate i2i_env jupyter lab In Jupyter Labs, navigate to spring_school_bioinformatics_microbiology/projects/project2/Project2C/ Then open the explore_data_bacmman.ipynb notebook Note on data","title":"Project 2C"},{"location":"project2/project-2C/#segmentation-and-tracking-mother-machine-data-with-bacmman-distnet","text":"Bacmman is a ImageJ plugin for analyzing mother machine data. All interactions with the software are via a GUI making it relatively user-friendly (though with a bit of a steep learning curve). At the backend Bacmman uses a state-of-the-art deep learning network to track and segment cells.","title":"Segmentation and Tracking Mother Machine Data with Bacmman &amp; DistNet"},{"location":"project2/project-2C/#download-data","text":"Important: the dataset is 5GB big, so start download at latest on Tuesday morning! cd I2ICourse mkdir Project2C cd Project2C wget -O RawData.zip https://drive.switch.ch/index.php/s/nwwP9spbricnFTW/download unzip -j RawData.zip Check the folder content (it should contain 2 tiff files). The remove the zip file with rm RawData.zip","title":"Download Data"},{"location":"project2/project-2C/#getting-started","text":"Note: parts of this tutorial have been adapted from this Wiki page of Jean Ollion. Bacmman is described extensively in this Nature Protocols article , however note that some parts are outdated. Specifically, the protocol uses the older, classical algorithm to track and segment cells. The parts that describe the GUI are still very useful though. More up-to-date info can be found on this wiki . The Distnet Deep Learning network is described in this publication .","title":"Getting started"},{"location":"project2/project-2C/#open-bacmman","text":"Open Fiji Go to Plugins -> Bacmman -> Bacteria in Mother Machine Analyzer","title":"Open Bacmman"},{"location":"project2/project-2C/#create-a-dataset","text":"","title":"Create a Dataset"},{"location":"project2/project-2C/#set-working-directory","text":"When using Bacmman for the first time choose a working directory. Right-click on the panel below Working Directory and select Choose Local Folder make a new folder in ~/I2ICourse/Project2C/Bacmman/ and select this one","title":"Set working directory"},{"location":"project2/project-2C/#create-new-data-set","text":"Click on Dataset menu and select New Dataset from Online Library Select dataset1_distnet When asked name it Project2C Note: after re-opening Bacmann you can re-open the dataset by double clicking on its name in the Dataset field","title":"Create new data set"},{"location":"project2/project-2C/#adapt-configuration-file","text":"Go to Configuration tab Right click on Import Method and select One file per Channel & Position The expand the Pre-Processing Template Go to Time Step and set to 7.5 (right click on value to change it). This is the time-interval, in minutes, between frames. Click on Dataset menu and select Save configuration changes","title":"Adapt configuration file"},{"location":"project2/project-2C/#add-image-data","text":"Go to Home tab Right click in Positions fields and select Import/re-link images Select the folder containing the Tiff Files: ~/I2ICourse/Project2C/RawData You should now see a list iof tiff images. You can inspect the data by right clicking on an image and select Open Input images .","title":"Add Image Data"},{"location":"project2/project-2C/#define-pre-processing-configuration","text":"","title":"Define Pre-processing Configuration"},{"location":"project2/project-2C/#preprocessing-steps","text":"Bacmman needs to do some pre-processing before the Distnet algorithm can segment cells. Specifically: Images should be cropped to only contain channels Images should be rotated if needed such that channels are vertically aligned Images should be flipped if needed such that channels points down Bacmman provides automated algorithms to do this, these can be adapted to fit your images. Unfortunately this does not always work. In fact, for our data we have been unable to find settings that work. However, we will still show you how to change the automated steps before skipping to manual pre-processing.","title":"Preprocessing steps"},{"location":"project2/project-2C/#test-automated-pre-processing-pipeline","text":"Go to Configuration Test Tab In Step select Pre-Processing For speed lets only test a few frames: right click on Frame Range and set range from 0 to 5 (you can reduce this further if needed) Let\u2019s try the AutoFlipY step that flips the microchannels. Right click on this step and select Test Transformation You can see the result looks bad: our channels were flipped even though they should not have (they should point down). Now try to find settings that work. Important spend max 5min on this!** Hint: you can right click on almost anything in Bacmmann to see and change settings. Hint: adapt the micro-channel height (doesn\u2019t have to be real length) Hint: if that does not work try changing the method It can be hard to find good settings, and some pre-processing might need to be done by hand. To remove an automated step, right click on it and select remove . You can add new modules. In the top right list are all Available Modules. To add one, right click on Pre-Processing Pipeline , this adds a new Transformation. Select this one, and then click on the desired module in the Available Modules list. Now change the config to the one shown in this screenshot: During testing this worked for us, please check! Then click on Copy to all position and copy to template Save the configuration via the Dataset menu","title":"Test automated pre-processing pipeline"},{"location":"project2/project-2C/#aside-setup-manual-pre-processing-pipeline","text":"Do not do this now, we use automated pipeline setup above! Sometimes finding automatic settings might be too hard, in that case you can then use manual cropping and flipping as shown in this screen shot: With the simple crop option, you need to set the crop box manually for each position. Important: for channels that point up, first add a Flip step. This should be done before the crop (see screenshot above). Test the SimpleCrop first with the default settings, this opens the image without cropping. Now you can draw a bounding box around the channels. Make sure to exclude the exits of the channels where there is a strong phase artifact, at the top keep a bit of space (10-20 pixels) to accommodate stage jitter (see screenshot). Write down the crop-box size and location and enter the numbers in the settings. Repeat this for all positions. Keep the full width of the image (do not change x-settings) and only change the y-values (see screenshot)","title":"Aside: Setup manual pre-processing pipeline"},{"location":"project2/project-2C/#run-pre-processing-pipeline","text":"To run pre-processing Select all positions Select the task: Pre-Processing Choose the menu command Run > Run Selected Tasks This step will take a while. To visualize the pre-processed images right-click on the position and choose Open Pre-Processed Images","title":"Run pre-processing pipeline"},{"location":"project2/project-2C/#configure-processing-pipeline","text":"The main processing pipeline does not need much configuration: the deep learning network takes care of almost everything. There are a couple things that we need to do though.","title":"Configure processing pipeline"},{"location":"project2/project-2C/#download-model-weights","text":"As DiSTNet is a deep-learning based method, it requires trained weights of the model. To download them (only needed first time you run Bacmman) Go to the Configuration Test tab In the Step panel select Processing In Object Class select Bacteria Unfold the parameters Tracker > Model > Tensorflow Model . The sub-parameter Model File appears in red if the model weights are not there. However it is possible to download them directly from BACMMAN. Right-click on Tensorflow Model and choose Download Model . The model weights will be downloaded at the path selected in the Model File parameter, that should not appear in red anymore after the download.","title":"Download Model Weights"},{"location":"project2/project-2C/#adapt-channel-width","text":"Go to the Configuration Test tab In the Step panel select Processing In Object Class select microchannels Set the channel width (in pixels) to the range seen in the data","title":"Adapt channel width"},{"location":"project2/project-2C/#run-tracking-and-segmentation","text":"Go back to the Home tab Select the objects Microchannels and Bacteria at the same time Select the task: Segmentation & Tracking Choose the menu command Run > Run Selected Tasks","title":"Run tracking and segmentation"},{"location":"project2/project-2C/#check-micro-channel-segmentation-and-tracking","text":"To visualize the result of microchannel segmentation and tracking: Go to the Data Browsing tab Right-click on the position and choose Open Hyperstack > Microchannels The pre-processed images will open as a interactive hyperstack (multi-channel & multi-frames image stack), on which microchannels can be selected. To display all segmented microchannels object use the shortcut crtl + A To display all microchannels tracks use the shortcut crtl + Q . Tracks will be displayed as colored contours, each color corresponding to one track. Note that the shortcut are available from the menu Help > Display Shortcut table and that a shortcut preset adapted for QWERTY keyboards can be chosen from the menu Help > Shortcut Presets","title":"Check micro-channel segmentation and tracking"},{"location":"project2/project-2C/#check-bacterial-segmentation-and-tracking","text":"To visualize the result of bacterial segmentation and tracking: Go to the Data Browsing tab Right-click on the position and choose Open Hyperstack > Bacteria The pre-processed images will open as a interactive hyperstack (multi-channel & multi-frames image stack), on which bacteria can be selected. To display all segmented bacteria object use the shortcut crtl + A To display all bacteria tracks use the shortcut crtl + Q . Tracks will be displayed as colored contours, each color corresponding to one track. Note that the shortcut are available from the menu Help > Display Shortcut table and that a shortcut preset adapted for QWERTY keyboards can be chosen from the menu Help > Shortcut Presets Another good way to visualize tracking is to use the Kymograph view: In the Segmentation & Tracking Results area, click on the arrow next to Position #0 to expand the list of micro channels. Right-click on a micro-channel and choose Open Kymograph > Bacteria The resulting image shows a concatenation of the same micro-channel for all time points To display all segmented bacteria object use the shortcut crtl + A To display all bacteria tracks use the shortcut crtl + Q . Tracks will be displayed as colored lines connecting neighboring time points.","title":"Check bacterial segmentation and tracking"},{"location":"project2/project-2C/#export-the-data","text":"Go to the Home tab Select the object Bacteria Select the tasks Measurements & Extract Measurements Choose the menu command Run > Run Selected Tasks","title":"Export the data"},{"location":"project2/project-2C/#post-process-with-python","text":"We will now switch to the cloud computers for the next steps.","title":"Post-process with Python"},{"location":"project2/project-2C/#create-project-folders-on-cloud-computer","text":"On the cloud computer, we have to make the project folders: cd ~/I2ICourse/ mkdir Project2C cd Project2C mkdir ProcessedData","title":"Create project folders on cloud computer"},{"location":"project2/project-2C/#transfer-the-data","text":"Then we have to transfer the data from your local computer to the cloud computer Upload the output file of Bacmann to a cloud drive, this file is located in: Create a public share link and copy the address cd ~/I2ICourse/Project2C/ProcessedData wget -O data.zip public_link_to_your_zip_file unzip -j data.zip","title":"Transfer the data"},{"location":"project2/project-2C/#launch-jupyter-labs","text":"Next navigate to the project folder, activate the conda environment, and launch Jupyter Labs: cd ~/I2ICourse/ conda activate i2i_env jupyter lab In Jupyter Labs, navigate to spring_school_bioinformatics_microbiology/projects/project2/Project2C/ Then open the explore_data_bacmman.ipynb notebook","title":"Launch Jupyter Labs"},{"location":"project2/project-2C/#note-on-data","text":"","title":"Note on data"},{"location":"project3/Overview/","text":"Overview of the project In this project","title":"Overview"},{"location":"project3/Overview/#overview-of-the-project","text":"In this project","title":"Overview of the project"},{"location":"project3/Prepare-before-start-of-the-course/","text":"Install software and packages To get started quickly during the course, we ask you to prepare a few things before the start of the course. We will use the following software: Trimmomatic fastQC mOTUs MAPseq SIAMCAT Please install these following the instructions below. Install four tools using Miniconda Conda is a package management system and environment management system that allow to quickly install, run and update packages and their dependencies. The first four tools can be easily installed using conda, we suggest to use Miniconda . After installing miniconda, create a file named NCCR_p3.yaml with: name: NCCR_p3 channels: - conda-forge - defaults - bioconda dependencies: - python = 3 .8 - fastqc = 0 .11.9 - motus = 3 .0.1 - trimmomatic = 0 .39 - mapseq = 1 .2.6 In the terminal you can then type: conda env create -f NCCR_p3.yaml To create an environment with the four tools that we will run in the terminal. You need to activate the environment before using it: source activate NCCR_p3 Note that mOTUs require around 7Gb of space and it will download 3.5 Gb when installing. Hence the installation can take a few minutes. Problems installing with conda If you have problem installing the conda environment, it might be due to the size required for mOTUs. We suggest to remove motus and install it with pip . First create a new yaml file (names NCCR_p3_test2.yaml ): name: NCCR_p3_test2 channels: - conda-forge - defaults - bioconda dependencies: - python = 3 .8 - fastqc = 0 .11.9 - bwa - samtools - pip - trimmomatic = 0 .39 - mapseq = 1 .2.6 Create and activate the environment: conda env create -f NCCR_p3_test2.yaml source activate NCCR_p3_test2 Install mOTUs with pip: pip install motu-profiler And download the database manually: motus downloadDB Installing R packages Within R (we suggest to use R studio), type: ##R Version 4.0.2 or above #tidyverse packages for plotting and data wrangling install.packages(\"tidyverse\") #SIAMCAT if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"SIAMCAT\")","title":"Preparation"},{"location":"project3/Prepare-before-start-of-the-course/#install-software-and-packages","text":"To get started quickly during the course, we ask you to prepare a few things before the start of the course. We will use the following software: Trimmomatic fastQC mOTUs MAPseq SIAMCAT Please install these following the instructions below.","title":"Install software and packages"},{"location":"project3/Prepare-before-start-of-the-course/#install-four-tools-using-miniconda","text":"Conda is a package management system and environment management system that allow to quickly install, run and update packages and their dependencies. The first four tools can be easily installed using conda, we suggest to use Miniconda . After installing miniconda, create a file named NCCR_p3.yaml with: name: NCCR_p3 channels: - conda-forge - defaults - bioconda dependencies: - python = 3 .8 - fastqc = 0 .11.9 - motus = 3 .0.1 - trimmomatic = 0 .39 - mapseq = 1 .2.6 In the terminal you can then type: conda env create -f NCCR_p3.yaml To create an environment with the four tools that we will run in the terminal. You need to activate the environment before using it: source activate NCCR_p3 Note that mOTUs require around 7Gb of space and it will download 3.5 Gb when installing. Hence the installation can take a few minutes.","title":"Install four tools using Miniconda"},{"location":"project3/Prepare-before-start-of-the-course/#problems-installing-with-conda","text":"If you have problem installing the conda environment, it might be due to the size required for mOTUs. We suggest to remove motus and install it with pip . First create a new yaml file (names NCCR_p3_test2.yaml ): name: NCCR_p3_test2 channels: - conda-forge - defaults - bioconda dependencies: - python = 3 .8 - fastqc = 0 .11.9 - bwa - samtools - pip - trimmomatic = 0 .39 - mapseq = 1 .2.6 Create and activate the environment: conda env create -f NCCR_p3_test2.yaml source activate NCCR_p3_test2 Install mOTUs with pip: pip install motu-profiler And download the database manually: motus downloadDB","title":"Problems installing with conda"},{"location":"project3/Prepare-before-start-of-the-course/#installing-r-packages","text":"Within R (we suggest to use R studio), type: ##R Version 4.0.2 or above #tidyverse packages for plotting and data wrangling install.packages(\"tidyverse\") #SIAMCAT if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"SIAMCAT\")","title":"Installing R packages"},{"location":"project3/Step-1/","text":"Step 1: Taxonomic profiling of metagenomic samples with mOTUs General note: this guide has been written assuming you use a Mac or Linux Command Line. Download example fastq files Sequencing data produced by a short read sequencer like Illumina result in two fastq files: forwards and reverse. You can download three example fastq files at the following links (within a terminal): wget https://www.embl.de/download/zeller/TEMP/NCCR_course/sample1_forward.fastq wget https://www.embl.de/download/zeller/TEMP/NCCR_course/sample1_reverse.fastq Check the quality of the sequencing data and filter out low quality reads You can evaluate the quality of fastq files with fastQC. For example run: fastqc raw_reads_forward.fastq Which will produce an html file. You can find more information on the different panels here: link You can filter out low quality reads using trimmomatic. You can find more information here . Note that if you installed trimmomatic with conda, you can run with trimmomatic PE [...] (do not need to specify java -jar trimmomatic-0.39.jar PE [...] ). How many reads have been filtered out? After filtering the reads, check if the overall quality improve.","title":"Step 1"},{"location":"project3/Step-1/#step-1-taxonomic-profiling-of-metagenomic-samples-with-motus","text":"General note: this guide has been written assuming you use a Mac or Linux Command Line.","title":"Step 1: Taxonomic profiling of metagenomic samples with mOTUs"},{"location":"project3/Step-1/#download-example-fastq-files","text":"Sequencing data produced by a short read sequencer like Illumina result in two fastq files: forwards and reverse. You can download three example fastq files at the following links (within a terminal): wget https://www.embl.de/download/zeller/TEMP/NCCR_course/sample1_forward.fastq wget https://www.embl.de/download/zeller/TEMP/NCCR_course/sample1_reverse.fastq","title":"Download example fastq files"},{"location":"project3/Step-1/#check-the-quality-of-the-sequencing-data-and-filter-out-low-quality-reads","text":"You can evaluate the quality of fastq files with fastQC. For example run: fastqc raw_reads_forward.fastq Which will produce an html file. You can find more information on the different panels here: link You can filter out low quality reads using trimmomatic. You can find more information here . Note that if you installed trimmomatic with conda, you can run with trimmomatic PE [...] (do not need to specify java -jar trimmomatic-0.39.jar PE [...] ). How many reads have been filtered out? After filtering the reads, check if the overall quality improve.","title":"Check the quality of the sequencing data and filter out low quality reads"},{"location":"project3/Step-2/","text":"Step 2: Comparative Metagenome Analysis with SIAMCAT General note: this guide has been written assuming you use a R. In R studio load the necessary libraries: library ( \"tidyverse\" ) # for general data wrangling and plotting library ( \"SIAMCAT\" ) # for statistical and machine learning analyses Download the taxonomic profiles and metadata From the previous step you learned how to create taxonomic profiles. Here we provide 120 taxonomic profiles in the form of a table where columns are samples and rows are species (or clade in general). Within R you can download and load the files with the following command: url_base = \"https://www.embl.de/download/zeller/TEMP/NCCR_course/\" # mOTUs species table feat.motus <- paste0 ( url_base , 'Wirbel_species.motus' ) tax.profiles <- read.table ( feat.motus , sep = '\\t' , quote = '' , comment.char = '' , skip = 2 , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) tax.profiles <- as.matrix ( tax.profiles ) Load the metadata with: meta.file <- paste0 ( url_base , 'Wirbel.metadata' ) meta <- read.table ( meta.file , sep = '\\t' , quote = '' , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) Examine the profiles and the metadata Look first at the taxonomic profiles and check how many zeros there are, what do they mean when you compare columns and rows zeros? The values in the taxonomic profiles represent read counts, if you compare the different samples (columns), do you observe a similar total read count? Can it be a problem when comparing species counts across different samples? Look at the metadata, how many control ( CTR ) and cases ( CRC for colorectal cancer) are there? Identify which species show an association to colorectal cancer patients How would you identify which species are associated to cancer? Which kind of test can you use? Explore how SIAMCAT identify associations between clades and phenotypes: link Build machine learning models to predict colorectal cancer patients from a metagenomic sample Explore the SIAMCAT basic vignette to understand how you can train machine learning models to predict colerectal cancer from metagenomic samples. Explore other profiling methods We profiled the same samples with different methods. Here you can load the mOTUs profiles at genus level (instead of species level): feat.motus <- paste0 ( url_base , 'Wirbel_genus.motus' ) tax.profiles.genus <- read.table ( feat.motus , sep = '\\t' , quote = '' , comment.char = '' , skip = 2 , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) tax.profiles.genus <- as.matrix ( tax.profiles.genus ) And here you can find the MAPseq profiles using 97% OTUs: feat.mapseq_97 = \"https://sunagawalab.ethz.ch/share/NCCR_spring_schools_2022/97_otutable_mapseq.csv\" mapseq.profiles97 <- read.table ( feat.mapseq_97 , sep = ',' , quote = '' , comment.char = '' , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) mapseq.profiles97 <- as.matrix ( mapseq.profiles97 ) If you replace \u201c97\u201d with \u201c99\u201d, you can download the profiles with 99% OTUs.","title":"Step 2"},{"location":"project3/Step-2/#step-2-comparative-metagenome-analysis-with-siamcat","text":"General note: this guide has been written assuming you use a R. In R studio load the necessary libraries: library ( \"tidyverse\" ) # for general data wrangling and plotting library ( \"SIAMCAT\" ) # for statistical and machine learning analyses","title":"Step 2: Comparative Metagenome Analysis with SIAMCAT"},{"location":"project3/Step-2/#download-the-taxonomic-profiles-and-metadata","text":"From the previous step you learned how to create taxonomic profiles. Here we provide 120 taxonomic profiles in the form of a table where columns are samples and rows are species (or clade in general). Within R you can download and load the files with the following command: url_base = \"https://www.embl.de/download/zeller/TEMP/NCCR_course/\" # mOTUs species table feat.motus <- paste0 ( url_base , 'Wirbel_species.motus' ) tax.profiles <- read.table ( feat.motus , sep = '\\t' , quote = '' , comment.char = '' , skip = 2 , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) tax.profiles <- as.matrix ( tax.profiles ) Load the metadata with: meta.file <- paste0 ( url_base , 'Wirbel.metadata' ) meta <- read.table ( meta.file , sep = '\\t' , quote = '' , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE )","title":"Download the taxonomic profiles and metadata"},{"location":"project3/Step-2/#examine-the-profiles-and-the-metadata","text":"Look first at the taxonomic profiles and check how many zeros there are, what do they mean when you compare columns and rows zeros? The values in the taxonomic profiles represent read counts, if you compare the different samples (columns), do you observe a similar total read count? Can it be a problem when comparing species counts across different samples? Look at the metadata, how many control ( CTR ) and cases ( CRC for colorectal cancer) are there?","title":"Examine the profiles and the metadata"},{"location":"project3/Step-2/#identify-which-species-show-an-association-to-colorectal-cancer-patients","text":"How would you identify which species are associated to cancer? Which kind of test can you use? Explore how SIAMCAT identify associations between clades and phenotypes: link","title":"Identify which species show an association to colorectal cancer patients"},{"location":"project3/Step-2/#build-machine-learning-models-to-predict-colorectal-cancer-patients-from-a-metagenomic-sample","text":"Explore the SIAMCAT basic vignette to understand how you can train machine learning models to predict colerectal cancer from metagenomic samples.","title":"Build machine learning models to predict colorectal cancer patients from a metagenomic sample"},{"location":"project3/Step-2/#explore-other-profiling-methods","text":"We profiled the same samples with different methods. Here you can load the mOTUs profiles at genus level (instead of species level): feat.motus <- paste0 ( url_base , 'Wirbel_genus.motus' ) tax.profiles.genus <- read.table ( feat.motus , sep = '\\t' , quote = '' , comment.char = '' , skip = 2 , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) tax.profiles.genus <- as.matrix ( tax.profiles.genus ) And here you can find the MAPseq profiles using 97% OTUs: feat.mapseq_97 = \"https://sunagawalab.ethz.ch/share/NCCR_spring_schools_2022/97_otutable_mapseq.csv\" mapseq.profiles97 <- read.table ( feat.mapseq_97 , sep = ',' , quote = '' , comment.char = '' , stringsAsFactors = FALSE , check.names = FALSE , row.names = 1 , header = TRUE ) mapseq.profiles97 <- as.matrix ( mapseq.profiles97 ) If you replace \u201c97\u201d with \u201c99\u201d, you can download the profiles with 99% OTUs.","title":"Explore other profiling methods"}]}